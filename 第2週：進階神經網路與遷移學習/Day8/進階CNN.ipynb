{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第二周的學習中，我們將進入 **進階 CNN 架構** 的領域，這是許多現代深度學習模型的基礎。\n",
    "\n",
    "在第八天的學習中，我們將介紹三個重要的進階 CNN 架構：**ResNet**、**VGG** 和 **Inception**。這些架構在圖像分類和目標檢測等任務中都表現出了卓越的性能，並被廣泛應用於各種深度學習項目中。\n",
    "\n",
    "---\n",
    "\n",
    "### **1. ResNet（Residual Networks）**\n",
    "\n",
    "#### **1.1 ResNet 的背景與動機**\n",
    "隨著神經網路的深度增加，出現了一個常見問題：**梯度消失和退化問題**。當網路越來越深時，模型的性能反而會下降，這是由於信息難以在多層之間有效傳遞。ResNet 提出了 **殘差連接（Residual Connections）** 的概念，通過跳過一部分網路層來保留信息流，從而解決了這一問題。\n",
    "\n",
    "#### **1.2 ResNet 的結構**\n",
    "ResNet 的核心思想是引入了一種**跳躍連接（Skip Connections）**，也稱為 **殘差塊（Residual Block）**。每個殘差塊通過跳躍連接允許網路學習**殘差（Residual）**，而不是直接學習輸出結果。\n",
    "\n",
    "#### **1.3 殘差塊結構**\n",
    "在 ResNet 中，殘差塊的結構如下：\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathcal{F}(x, \\{W_i\\}) + x\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $x$ 是輸入，\n",
    "- $\\mathcal{F}(x, \\{W_i\\})$ 是經過一系列卷積操作後的輸出，\n",
    "- $x$ 是通過跳躍連接直接加回的輸入。\n",
    "\n",
    "這樣的結構可以使得模型更容易學習到有效的特徵，並且隨著層數的增加不會導致梯度消失。\n",
    "\n",
    "#### **1.4 ResNet 變體**\n",
    "- **ResNet-18/34/50/101/152**：這些變體通過堆疊更多的殘差塊來構建更深的網路，層數越多，網路越深。\n",
    "- **ResNet-50 和 ResNet-101**：這些模型常用於圖像分類任務，如 ImageNet。\n",
    "\n",
    "---\n",
    "\n",
    "### **2. VGGNet（Visual Geometry Group Network）**\n",
    "\n",
    "#### **2.1 VGGNet 的背景**\n",
    "VGGNet 是由牛津大學的 Visual Geometry Group 提出的，它通過使用一系列相對小的卷積核（如 $3 \\times 3$）來構建深度 CNN。在 VGGNet 中，卷積層之後會緊接著一個池化層，並最終經過全連接層進行分類。\n",
    "\n",
    "#### **2.2 VGGNet 的結構**\n",
    "VGGNet 的結構相對簡單，它主要由重複的 **卷積層** 和 **池化層** 組成。VGGNet 使用非常小的 $3 \\times 3$ 卷積核，通過堆疊多層來增加網路的深度，並且每當特徵圖的尺寸縮小一半時，通過池化層進行降維。\n",
    "\n",
    "#### **2.3 VGGNet 變體**\n",
    "- **VGG-16**：包含 16 層權重層，這是最經典的 VGGNet 版本。\n",
    "- **VGG-19**：比 VGG-16 更深，包含 19 層權重層。\n",
    "\n",
    "VGGNet 的優點是結構簡單，易於理解和實作，但缺點是模型參數非常多，對計算資源需求較高。\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Inception（GoogLeNet）**\n",
    "\n",
    "#### **3.1 Inception 的背景**\n",
    "Inception（又稱 GoogLeNet）是在解決卷積神經網路的計算效率問題時提出的。它的設計思想是通過不同尺度的卷積核來並行處理圖像的不同特徵，這樣可以同時捕捉到局部和全局特徵。\n",
    "\n",
    "#### **3.2 Inception 模塊**\n",
    "Inception 的核心是 **Inception 模塊**，每個模塊內包含不同大小的卷積核，如 $1 \\times 1$、$3 \\times 3$ 和 $5 \\times 5$。此外，還包含一個 **最大池化層**，這樣的並行結構能夠有效利用網路資源，並且捕捉不同尺度的特徵。\n",
    "\n",
    "#### **3.3 Inception 模塊結構**\n",
    "Inception 模塊的基本結構如下：\n",
    "- 使用 $1 \\times 1$ 卷積核進行降維，減少計算量。\n",
    "- 使用 $3 \\times 3$ 和 $5 \\times 5$ 卷積核提取特徵。\n",
    "- 使用最大池化層進行下採樣，減少圖像的維度。\n",
    "\n",
    "#### **3.4 Inception 變體**\n",
    "- **GoogLeNet（Inception v1）**：首次提出 Inception 架構，使用多尺度卷積核進行特徵提取。\n",
    "- **Inception v2/v3/v4**：在不同版本中進行了優化，如使用因式分解卷積核來進一步降低計算量。\n",
    "\n",
    "Inception 系列的特點是 **計算高效且性能優異**，因此在實際應用中非常常見。\n",
    "\n",
    "---\n",
    "\n",
    "### **4. 進階 CNN 架構總結與比較**\n",
    "\n",
    "- **ResNet**：解決了網路深度增加時的梯度消失和退化問題。它的殘差塊設計允許信息在多層之間流動，因此可以構建非常深的網路。\n",
    "- **VGGNet**：結構簡單，使用小卷積核和深層網路來進行特徵提取，但計算和存儲成本較高。\n",
    "- **Inception（GoogLeNet）**：通過多尺度卷積核的設計，同時捕捉局部和全局特徵，並且計算效率較高。\n",
    "\n",
    "每一種進階 CNN 架構都有其獨特的應用場景，你可以根據具體任務選擇合適的架構來提高模型性能。\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
